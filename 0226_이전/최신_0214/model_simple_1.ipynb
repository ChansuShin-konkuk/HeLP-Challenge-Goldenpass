{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import openslide\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "# 이부분 python 에서는 뺴주기\n",
    "\n",
    "from skimage.filters import threshold_otsu\n",
    "from openslide.deepzoom import DeepZoomGenerator\n",
    "import cv2\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Lambda, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.models import load_model\n",
    "\n",
    "# Unet\n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "import skimage.transform as trans\n",
    "#import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "\n",
    "\n",
    "# train\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from datetime import datetime\n",
    "\n",
    "# evaluate\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "from PIL import Image\n",
    "from xml.etree.ElementTree import ElementTree, Element, SubElement\n",
    "from io import BytesIO\n",
    "import skimage.io as io\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "#print(device_lib.list_local_devices())\n",
    "import keras.backend.tensorflow_backend as K\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.preprocessing.image import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 256\n",
    "IS_TRAIN = True\n",
    "def find_patches_from_slide(slide_path, truth_path, patch_size=PATCH_SIZE,filter_non_tissue=True,filter_only_all_tumor=True):\n",
    "    \n",
    "    slide_contains_tumor = 'pos' in slide_path\n",
    "    \n",
    "    ############### read_region을 위한 start, level, size를 구함 #######################\n",
    "    BOUNDS_OFFSET_PROPS = (openslide.PROPERTY_NAME_BOUNDS_X, openslide.PROPERTY_NAME_BOUNDS_Y)\n",
    "    BOUNDS_SIZE_PROPS = (openslide.PROPERTY_NAME_BOUNDS_WIDTH, openslide.PROPERTY_NAME_BOUNDS_HEIGHT)\n",
    "\n",
    "    if slide_contains_tumor:\n",
    "        with openslide.open_slide(slide_path) as slide:\n",
    "            start = (int(slide.properties.get('openslide.bounds-x',0)),int(slide.properties.get('openslide.bounds-y',0)))\n",
    "            level = np.log2(patch_size) \n",
    "            level = int(level)\n",
    "            \n",
    "            size_scale = tuple(int(slide.properties.get(prop, l0_lim)) / l0_lim\n",
    "                            for prop, l0_lim in zip(BOUNDS_SIZE_PROPS,\n",
    "                            slide.dimensions))\n",
    "            _l_dimensions = tuple(tuple(int(math.ceil(l_lim * scale))\n",
    "                            for l_lim, scale in zip(l_size, size_scale))\n",
    "                            for l_size in slide.level_dimensions)\n",
    "            size = _l_dimensions[level]\n",
    "            \n",
    "            slide4 = slide.read_region(start,level,size) \n",
    "    else :\n",
    "        with openslide.open_slide(slide_path) as slide:\n",
    "            start = (0,0)\n",
    "            level = np.log2(patch_size) \n",
    "            level = int(level)\n",
    "            \n",
    "            size_scale = (1,1)\n",
    "            _l_dimensions = tuple(tuple(int(math.ceil(l_lim * scale))\n",
    "                            for l_lim, scale in zip(l_size, size_scale))\n",
    "                            for l_size in slide.level_dimensions)\n",
    "            size = _l_dimensions[level]\n",
    "            \n",
    "            slide4 = slide.read_region(start,level,size) \n",
    "    ####################################################################################\n",
    "    \n",
    "    \n",
    "    # is_tissue 부분 \n",
    "    slide4_grey = np.array(slide4.convert('L'))\n",
    "    binary = slide4_grey > 0  # black이면 0임\n",
    "    \n",
    "    # 검은색 제외하고 흰색영역(배경이라고 여겨지는)에 대해서도 작업해주어야함.\n",
    "    slide4_not_black = slide4_grey[slide4_grey>0]\n",
    "    thresh = threshold_otsu(slide4_not_black)\n",
    "    \n",
    "    I, J = slide4_grey.shape\n",
    "    for i in range(I):\n",
    "        for j in range(J):\n",
    "            if slide4_grey[i,j] > thresh :\n",
    "                binary[i,j] = False\n",
    "    patches = pd.DataFrame(pd.DataFrame(binary).stack())\n",
    "    patches['is_tissue'] = patches[0]\n",
    "    patches.drop(0, axis=1,inplace =True)\n",
    "    patches.loc[:,'slide_path'] = slide_path\n",
    "    \n",
    "#     # Test 이면 \n",
    "#     if IS_TEST:\n",
    "#         return patches\n",
    "\n",
    "    # is_tumor 부분\n",
    "    if slide_contains_tumor:\n",
    "        with openslide.open_slide(truth_path) as truth:\n",
    "            thumbnail_truth = truth.get_thumbnail(size) \n",
    "        \n",
    "        patches_y = pd.DataFrame(pd.DataFrame(np.array(thumbnail_truth.convert(\"L\"))).stack())\n",
    "        patches_y['is_tumor'] = patches_y[0] > 0\n",
    "        \n",
    "        # mask된 영역이 애매할 수도 있으므로\n",
    "        patches_y['is_all_tumor'] = patches_y[0] == 255\n",
    "        patches_y.drop(0, axis=1, inplace=True)\n",
    "        samples = pd.concat([patches, patches_y], axis=1) #len(samples)\n",
    "    else:\n",
    "        samples = patches\n",
    "        #dfmi.loc[:,('one','second')] = value\n",
    "        samples.loc[:,'is_tumor'] = False\n",
    "        samples.loc[:,'is_all_tumor'] = False\n",
    "    \n",
    "    if filter_non_tissue:\n",
    "        samples = samples[samples.is_tissue == True] # remove patches with no tissue #samples = samples[samples.is_tissue == True]\n",
    "    \n",
    "    if filter_only_all_tumor :\n",
    "        samples['tile_loc'] = list(samples.index)\n",
    "        all_tissue_samples1 = samples[samples.is_tumor==False]\n",
    "        all_tissue_samples1 = all_tissue_samples1.append(samples[samples.is_all_tumor==True])\n",
    "        \n",
    "        all_tissue_samples1.reset_index(inplace=True, drop=True)\n",
    "    else :\n",
    "        return samples\n",
    "    \n",
    "    return all_tissue_samples1\n",
    "NUM_CLASSES = 2 # not_tumor, tumor\n",
    "\n",
    "file_handles=[]\n",
    "def gen_imgs(all_image_path, all_mask_path, samples, batch_size, patch_size = PATCH_SIZE, shuffle=True):\n",
    "   \n",
    "    num_samples = len(samples)\n",
    "    # 특정 몇개의 slide만 open 해서 쓰기\n",
    "    # 4개씩 묶었으니까 \n",
    "  \n",
    "    slide_path0 = all_image_path[0]\n",
    "    slide_path1 = all_image_path[1]\n",
    "    slide_path2 = all_image_path[2]\n",
    "    slide_path3 = all_image_path[3]\n",
    "    \n",
    "    \n",
    "    # slide 0~3 까지 미리 열어두기\n",
    "    slide0 = openslide.open_slide(slide_path0)\n",
    "    slide1 = openslide.open_slide(slide_path1)\n",
    "    slide2 = openslide.open_slide(slide_path2)\n",
    "    slide3 = openslide.open_slide(slide_path3)\n",
    "    file_handles.append(slide0)\n",
    "    file_handles.append(slide1)\n",
    "    file_handles.append(slide2)\n",
    "    file_handles.append(slide3)\n",
    "    \n",
    "    # with openslide.open_slide(slide_path) as slide\n",
    "    tiles0 = DeepZoomGenerator(slide0,tile_size=patch_size, overlap=0, limit_bounds=False) \n",
    "    tiles1 = DeepZoomGenerator(slide1,tile_size=patch_size, overlap=0, limit_bounds=False)\n",
    "    tiles2 = DeepZoomGenerator(slide2,tile_size=patch_size, overlap=0, limit_bounds=False)\n",
    "    tiles3 = DeepZoomGenerator(slide3,tile_size=patch_size, overlap=0, limit_bounds=False)\n",
    "    \n",
    "    \n",
    "    if 'pos' in slide_path0:\n",
    "        start_x0 = int(slide0.properties.get('openslide.bounds-x',0))\n",
    "        start_y0 = int(slide0.properties.get('openslide.bounds-y',0))\n",
    "        start_x0 = start_x0 / patch_size\n",
    "        start_y0 = start_y0 / patch_size\n",
    "        \n",
    "        truth0 = openslide.open_slide(all_mask_path[0])\n",
    "        truth_tiles0 = DeepZoomGenerator(truth0, tile_size=16, overlap=0, limit_bounds=False) \n",
    "        \n",
    "    else : \n",
    "        start_x0 = 0\n",
    "        start_y0 = 0\n",
    "    \n",
    "    if 'pos' in slide_path1:\n",
    "        start_x1 = int(slide1.properties.get('openslide.bounds-x',0))\n",
    "        start_y1 = int(slide1.properties.get('openslide.bounds-y',0))\n",
    "        start_x1 = start_x1 / patch_size\n",
    "        start_y1 = start_y1 / patch_size\n",
    "        \n",
    "        truth1 = openslide.open_slide(all_mask_path[1])\n",
    "        truth_tiles1 = DeepZoomGenerator(truth1, tile_size=16, overlap=0, limit_bounds=False) \n",
    "        \n",
    "    else : \n",
    "        start_x1 = 0\n",
    "        start_y1 = 0\n",
    "    \n",
    "    if 'pos' in slide_path2:\n",
    "        start_x2 = int(slide2.properties.get('openslide.bounds-x',0))\n",
    "        start_y2 = int(slide2.properties.get('openslide.bounds-y',0))\n",
    "        start_x2 = start_x2 / patch_size\n",
    "        start_y2 = start_y2 / patch_size\n",
    "        \n",
    "        truth2 = openslide.open_slide(all_mask_path[2])\n",
    "        truth_tiles2 = DeepZoomGenerator(truth2, tile_size=16, overlap=0, limit_bounds=False) \n",
    "        \n",
    "    else : \n",
    "        start_x2 = 0\n",
    "        start_y2 = 0\n",
    "        \n",
    "    if 'pos' in slide_path3:\n",
    "        start_x3 = int(slide3.properties.get('openslide.bounds-x',0))\n",
    "        start_y3 = int(slide3.properties.get('openslide.bounds-y',0))\n",
    "        start_x3 = start_x3 / patch_size\n",
    "        start_y3 = start_y3 / patch_size\n",
    "        \n",
    "        truth3 = openslide.open_slide(all_mask_path[3])\n",
    "        truth_tiles3 = DeepZoomGenerator(truth3, tile_size=16, overlap=0, limit_bounds=False) \n",
    "        \n",
    "    else : \n",
    "        start_x3 = 0\n",
    "        start_y3 = 0\n",
    "    \n",
    "\n",
    "    \n",
    "    for epo in range(10): # Loop forever so the generator never terminates\n",
    "        if shuffle:\n",
    "            samples = samples.sample(frac=1) # shuffle samples\n",
    "\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples.iloc[offset:offset+batch_size]\n",
    "            images = []\n",
    "            masks = []\n",
    "            for _, batch_sample in batch_samples.iterrows(): # 배치마다 deep zoom 하네 약간 비효율적\n",
    "                \n",
    "                # 여기서 하나씩 4개 체크해서 해당되는 부분으로 가야지. for 4번 돌리면서 가야한다.\n",
    "                mask_size_up = np.zeros((patch_size,patch_size))\n",
    "                a,b=mask_size_up.shape\n",
    "                \n",
    "                if batch_sample.slide_path == slide_path0:\n",
    "                    x, y = batch_sample.tile_loc[::-1]\n",
    "                    x += start_x0\n",
    "                    y += start_y0\n",
    "                    img = tiles0.get_tile(tiles0.level_count-1, (x,y))\n",
    "                    if 'pos' in slide_path0:\n",
    "                        mask = truth_tiles0.get_tile(truth_tiles0.level_count-1, batch_sample.tile_loc[::-1])\n",
    "                        mask = (cv2.cvtColor(np.array(mask), cv2.COLOR_RGB2GRAY) > 0).astype(int)\n",
    "                            # mask_size_up , 16 to 256\n",
    "                        for i in range(a):\n",
    "                            for j in range(b) :\n",
    "                                k = i//16\n",
    "                                l = j//16\n",
    "                                mask_size_up[i,j] = mask[k,l]\n",
    "                    \n",
    "                elif batch_sample.slide_path == slide_path1:\n",
    "                    x, y = batch_sample.tile_loc[::-1]\n",
    "                    x += start_x1\n",
    "                    y += start_y1\n",
    "                    img = tiles1.get_tile(tiles1.level_count-1, (x,y))\n",
    "                    if 'pos' in slide_path1:\n",
    "                        mask = truth_tiles1.get_tile(truth_tiles1.level_count-1, batch_sample.tile_loc[::-1])\n",
    "                        mask = (cv2.cvtColor(np.array(mask), cv2.COLOR_RGB2GRAY) > 0).astype(int)\n",
    "                            # mask_size_up , 16 to 256\n",
    "                        for i in range(a):\n",
    "                            for j in range(b) :\n",
    "                                k = i//16\n",
    "                                l = j//16\n",
    "                                mask_size_up[i,j] = mask[k,l]\n",
    "                \n",
    "                elif batch_sample.slide_path == slide_path2:\n",
    "                    x, y = batch_sample.tile_loc[::-1]\n",
    "                    x += start_x2\n",
    "                    y += start_y2\n",
    "                    img = tiles2.get_tile(tiles2.level_count-1, (x,y))\n",
    "                    if 'pos' in slide_path2:\n",
    "                        mask = truth_tiles2.get_tile(truth_tiles2.level_count-1, batch_sample.tile_loc[::-1])\n",
    "                        mask = (cv2.cvtColor(np.array(mask), cv2.COLOR_RGB2GRAY) > 0).astype(int)\n",
    "                            # mask_size_up , 16 to 256\n",
    "                        for i in range(a):\n",
    "                            for j in range(b) :\n",
    "                                k = i//16\n",
    "                                l = j//16\n",
    "                                mask_size_up[i,j] = mask[k,l]\n",
    "                \n",
    "                else:\n",
    "                    x, y = batch_sample.tile_loc[::-1]\n",
    "                    x += start_x3\n",
    "                    y += start_y3\n",
    "                    img = tiles3.get_tile(tiles3.level_count-1, (x,y))\n",
    "                    if 'pos' in slide_path3:\n",
    "                        mask = truth_tiles3.get_tile(truth_tiles3.level_count-1, batch_sample.tile_loc[::-1])\n",
    "                        mask = (cv2.cvtColor(np.array(mask), cv2.COLOR_RGB2GRAY) > 0).astype(int)\n",
    "                            # mask_size_up , 16 to 256\n",
    "                        for i in range(a):\n",
    "                            for j in range(b) :\n",
    "                                k = i//16\n",
    "                                l = j//16\n",
    "                                mask_size_up[i,j] = mask[k,l]\n",
    "                \n",
    "                    \n",
    "\n",
    "                images.append(np.array(img))\n",
    "                masks.append(mask_size_up)\n",
    "\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(masks)\n",
    "            #print('x_train_shape :', X_train.shape)\n",
    "            \n",
    "            y_train = to_categorical(y_train, num_classes=2).reshape(y_train.shape[0], patch_size, patch_size, 2) \n",
    "            #print('y_train_shape : ',y_train.shape)\n",
    "            \n",
    "            #X_train, y_train = datagen().flow(X_train,y = y_train,batch_size = batch_size)\n",
    "            X_train, y_train = next(ImageDataGenerator(\n",
    "                rotation_range=90,\n",
    "                horizontal_flip=True,\n",
    "                vertical_flip=True,\n",
    "                brightness_range =(0.25,1.)).flow(X_train,y=y_train,batch_size=batch_size))\n",
    "            #print(X_train.shape)\n",
    "            #print(y_train.shape)\n",
    "            yield X_train, y_train\n",
    "            \n",
    "def predict_batch_from_model(patches, model):\n",
    "    \"\"\"Predict which pixels are tumor.\n",
    "    \n",
    "    input: patch: `batch_size`x256x256x3, rgb image\n",
    "    input: model: keras model\n",
    "    output: prediction: 256x256x1, per-pixel tumor probability\n",
    "    \"\"\"\n",
    "    predictions = model.predict(patches)\n",
    "    predictions = predictions[:, :, :, 1]\n",
    "    return predictions\n",
    "def predict_from_model(patch, model):\n",
    "    \"\"\"Predict which pixels are tumor.\n",
    "    \n",
    "    input: patch: 256x256x3, rgb image\n",
    "    input: model: keras model\n",
    "    output: prediction: 256x256x1, per-pixel tumor probability\n",
    "    \"\"\"\n",
    "    \n",
    "    prediction = model.predict(patch.reshape(1, 256, 256, 3))\n",
    "    prediction = prediction[:, :, :, 1].reshape(256, 256)\n",
    "    return prediction\n",
    "\n",
    "def predict_from_model_n(patch, model):\n",
    "    \"\"\"Predict which pixels are tumor.\n",
    "    \n",
    "    input: patch: 256x256x3, rgb image\n",
    "    input: model: keras model\n",
    "    output: prediction: 256x256x1, per-pixel tumor probability\n",
    "    \"\"\"\n",
    "    \n",
    "    prediction = model.predict(patch.reshape(1, 256, 256, 3))\n",
    "    prediction = prediction[:, :, :, 0].reshape(256, 256)\n",
    "    return prediction\n",
    "\n",
    "def simple_model(pretrained_weights = None):\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=(256, 256, 3)))\n",
    "    model.add(Convolution2D(100, (3, 3), strides=(2, 2), activation='elu', padding='same'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Convolution2D(200, (3, 3), strides=(2, 2), activation='elu', padding='same'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Convolution2D(300, (3, 3), activation='elu', padding='same'))\n",
    "    model.add(Convolution2D(300, (3, 3), activation='elu',  padding='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Convolution2D(2, (1, 1))) # this is called upscore layer for some reason?\n",
    "    model.add(Conv2DTranspose(2, (31, 31), strides=(16, 16), activation='softmax', padding='same'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    if(pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_path # :  157\n",
      "mask_patch # :  157\n"
     ]
    }
   ],
   "source": [
    "def read_data_path():\n",
    "    image_paths = []\n",
    "    with open('train.txt','r') as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip('\\n')\n",
    "            image_paths.append(line)\n",
    "    #print('image_path # : ',len(image_paths))\n",
    "\n",
    "    tumor_mask_paths = []\n",
    "\n",
    "    with open('train_mask.txt','r') as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip('\\n')\n",
    "            tumor_mask_paths.append(line)\n",
    "    #print('mask_patch # : ',len(tumor_mask_paths))\n",
    "    \n",
    "    return image_paths, tumor_mask_paths\n",
    "\n",
    "def read_test_data_path():\n",
    "    image_paths = []\n",
    "    with open('test.txt','r') as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip('\\n')\n",
    "            image_paths.append(line)\n",
    "    #print('image_path # : ',len(image_paths))\n",
    "    \n",
    "    return image_paths\n",
    "\n",
    "test_image_paths = read_test_data_path()\n",
    "image_paths, tumor_mask_paths = read_data_path()\n",
    "image_paths = []\n",
    "with open('train.txt','r') as f:\n",
    "    for line in f:\n",
    "        line = line.rstrip('\\n')\n",
    "        image_paths.append(line)\n",
    "print('image_path # : ',len(image_paths))\n",
    "\n",
    "tumor_mask_paths = []\n",
    "with open('train_mask.txt','r') as f:\n",
    "    for line in f:\n",
    "        line = line.rstrip('\\n')\n",
    "        tumor_mask_paths.append(line)\n",
    "print('mask_patch # : ',len(tumor_mask_paths))\n",
    "\n",
    "slide_4_list_1 = [[102,104,29,44],[144,55,30,18],[125,56,35,40],[54,65,21,36],[139,82,1,49],[73,108,7,23],[107,117,24,52],[106,103,27,13]\n",
    "               ,[105,151,15,2],[75,100,41,9],[156,113,32,37],[150,88,39,10],[84,122,5,50],[93,118,53,47],[87,78,45,34],[116,98,48,46],\n",
    "                [72,131,22,42]]\n",
    "slide_4_list_2 = [[109,58,14,28],[101,69,11,43],[94,74,3,20],[64,140,17,16],[92,154,8,26],[99,60,0,33],[86,146,25,19],[68,112,38,51],\n",
    "                 [71,136,31,4],[59,91,12,6]]\n",
    "slide_4_list_3 = [[143,132,124,85],[95,120,81,77],[97,96,110,83],[152,128,149,155],[153,111,57,138],[134,135,114,76],\n",
    "                  [123,90,121,61],[147,148,119,142],[66,137,63,80],[70,79,115,133],[129,141,127,145]]\n",
    "slide_4_test = [[55,55,0,0],[55,55,0,0]]\n",
    "\n",
    "all_image_path = []\n",
    "all_mask_path = []\n",
    "for j in range(4):\n",
    "    image_path = image_paths[slide_4_test[0][j]][1:] # 이 부분은 data 읽을때 고치자 ( [1:] 빼야함)\n",
    "    mask_path = tumor_mask_paths[slide_4_test[0][j]][1:] # 이 부분은 data 읽을때 고치자\n",
    "    all_image_path.append(image_path)\n",
    "    all_mask_path.append(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simple_model('s_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61446\n",
      "160136\n",
      "Epoch 1/2\n",
      "147/352 [===========>..................] - ETA: 1:11:00 - loss: 0.1353 - acc: 0.94 - ETA: 55:08 - loss: 0.1231 - acc: 0.9518 - ETA: 53:44 - loss: 0.1113 - acc: 0.95 - ETA: 52:52 - loss: 0.1540 - acc: 0.94 - ETA: 52:22 - loss: 0.1444 - acc: 0.94 - ETA: 51:55 - loss: 0.1430 - acc: 0.94 - ETA: 51:29 - loss: 0.1445 - acc: 0.94 - ETA: 51:09 - loss: 0.1414 - acc: 0.94 - ETA: 50:49 - loss: 0.1400 - acc: 0.94 - ETA: 50:36 - loss: 0.1389 - acc: 0.94 - ETA: 50:22 - loss: 0.1376 - acc: 0.94 - ETA: 48:53 - loss: 0.1350 - acc: 0.94 - ETA: 47:40 - loss: 0.1297 - acc: 0.95 - ETA: 46:34 - loss: 0.1307 - acc: 0.95 - ETA: 45:35 - loss: 0.1310 - acc: 0.95 - ETA: 44:43 - loss: 0.1297 - acc: 0.95 - ETA: 43:57 - loss: 0.1302 - acc: 0.95 - ETA: 43:16 - loss: 0.1315 - acc: 0.95 - ETA: 42:39 - loss: 0.1304 - acc: 0.95 - ETA: 42:05 - loss: 0.1287 - acc: 0.95 - ETA: 41:33 - loss: 0.1290 - acc: 0.95 - ETA: 41:04 - loss: 0.1287 - acc: 0.95 - ETA: 40:36 - loss: 0.1286 - acc: 0.95 - ETA: 40:11 - loss: 0.1286 - acc: 0.95 - ETA: 39:46 - loss: 0.1281 - acc: 0.95 - ETA: 39:23 - loss: 0.1270 - acc: 0.95 - ETA: 39:03 - loss: 0.1286 - acc: 0.95 - ETA: 38:42 - loss: 0.1281 - acc: 0.95 - ETA: 38:24 - loss: 0.1283 - acc: 0.95 - ETA: 38:06 - loss: 0.1274 - acc: 0.95 - ETA: 37:49 - loss: 0.1274 - acc: 0.95 - ETA: 37:32 - loss: 0.1282 - acc: 0.95 - ETA: 37:14 - loss: 0.1269 - acc: 0.95 - ETA: 36:57 - loss: 0.1269 - acc: 0.95 - ETA: 36:41 - loss: 0.1268 - acc: 0.95 - ETA: 36:27 - loss: 0.1254 - acc: 0.95 - ETA: 36:16 - loss: 0.1247 - acc: 0.95 - ETA: 36:00 - loss: 0.1243 - acc: 0.95 - ETA: 35:45 - loss: 0.1227 - acc: 0.95 - ETA: 35:31 - loss: 0.1218 - acc: 0.95 - ETA: 35:19 - loss: 0.1218 - acc: 0.95 - ETA: 35:06 - loss: 0.1210 - acc: 0.95 - ETA: 34:53 - loss: 0.1212 - acc: 0.95 - ETA: 34:41 - loss: 0.1216 - acc: 0.95 - ETA: 34:28 - loss: 0.1206 - acc: 0.95 - ETA: 34:16 - loss: 0.1204 - acc: 0.95 - ETA: 34:04 - loss: 0.1206 - acc: 0.95 - ETA: 33:53 - loss: 0.1201 - acc: 0.95 - ETA: 33:42 - loss: 0.1194 - acc: 0.95 - ETA: 33:31 - loss: 0.1199 - acc: 0.95 - ETA: 33:20 - loss: 0.1200 - acc: 0.95 - ETA: 33:08 - loss: 0.1191 - acc: 0.95 - ETA: 32:58 - loss: 0.1189 - acc: 0.95 - ETA: 32:48 - loss: 0.1194 - acc: 0.95 - ETA: 32:38 - loss: 0.1203 - acc: 0.95 - ETA: 32:28 - loss: 0.1207 - acc: 0.95 - ETA: 32:18 - loss: 0.1201 - acc: 0.95 - ETA: 32:08 - loss: 0.1199 - acc: 0.95 - ETA: 31:58 - loss: 0.1204 - acc: 0.95 - ETA: 31:49 - loss: 0.1205 - acc: 0.95 - ETA: 31:39 - loss: 0.1203 - acc: 0.95 - ETA: 31:29 - loss: 0.1198 - acc: 0.95 - ETA: 31:20 - loss: 0.1196 - acc: 0.95 - ETA: 31:11 - loss: 0.1198 - acc: 0.95 - ETA: 31:02 - loss: 0.1194 - acc: 0.95 - ETA: 30:53 - loss: 0.1205 - acc: 0.95 - ETA: 30:44 - loss: 0.1206 - acc: 0.95 - ETA: 30:37 - loss: 0.1200 - acc: 0.95 - ETA: 30:29 - loss: 0.1197 - acc: 0.95 - ETA: 30:20 - loss: 0.1197 - acc: 0.95 - ETA: 30:12 - loss: 0.1198 - acc: 0.95 - ETA: 30:03 - loss: 0.1199 - acc: 0.95 - ETA: 29:55 - loss: 0.1199 - acc: 0.95 - ETA: 29:47 - loss: 0.1197 - acc: 0.95 - ETA: 29:39 - loss: 0.1195 - acc: 0.95 - ETA: 29:31 - loss: 0.1192 - acc: 0.95 - ETA: 29:23 - loss: 0.1192 - acc: 0.95 - ETA: 29:15 - loss: 0.1188 - acc: 0.95 - ETA: 29:07 - loss: 0.1189 - acc: 0.95 - ETA: 29:00 - loss: 0.1194 - acc: 0.95 - ETA: 28:52 - loss: 0.1191 - acc: 0.95 - ETA: 28:44 - loss: 0.1186 - acc: 0.95 - ETA: 28:37 - loss: 0.1186 - acc: 0.95 - ETA: 28:29 - loss: 0.1185 - acc: 0.95 - ETA: 28:21 - loss: 0.1193 - acc: 0.95 - ETA: 28:14 - loss: 0.1192 - acc: 0.95 - ETA: 28:06 - loss: 0.1193 - acc: 0.95 - ETA: 27:59 - loss: 0.1199 - acc: 0.95 - ETA: 27:51 - loss: 0.1203 - acc: 0.95 - ETA: 27:44 - loss: 0.1202 - acc: 0.95 - ETA: 27:36 - loss: 0.1199 - acc: 0.95 - ETA: 27:29 - loss: 0.1198 - acc: 0.95 - ETA: 27:21 - loss: 0.1200 - acc: 0.95 - ETA: 27:14 - loss: 0.1201 - acc: 0.95 - ETA: 27:07 - loss: 0.1201 - acc: 0.95 - ETA: 27:00 - loss: 0.1200 - acc: 0.95 - ETA: 26:53 - loss: 0.1202 - acc: 0.95 - ETA: 26:46 - loss: 0.1204 - acc: 0.95 - ETA: 26:39 - loss: 0.1202 - acc: 0.95 - ETA: 26:32 - loss: 0.1199 - acc: 0.95 - ETA: 26:25 - loss: 0.1196 - acc: 0.95 - ETA: 26:18 - loss: 0.1194 - acc: 0.95 - ETA: 26:10 - loss: 0.1197 - acc: 0.95 - ETA: 26:03 - loss: 0.1198 - acc: 0.95 - ETA: 25:56 - loss: 0.1196 - acc: 0.95 - ETA: 25:48 - loss: 0.1194 - acc: 0.95 - ETA: 25:41 - loss: 0.1194 - acc: 0.95 - ETA: 25:34 - loss: 0.1198 - acc: 0.95 - ETA: 25:27 - loss: 0.1195 - acc: 0.95 - ETA: 25:20 - loss: 0.1196 - acc: 0.95 - ETA: 25:13 - loss: 0.1193 - acc: 0.95 - ETA: 25:05 - loss: 0.1192 - acc: 0.95 - ETA: 24:58 - loss: 0.1194 - acc: 0.95 - ETA: 24:51 - loss: 0.1192 - acc: 0.95 - ETA: 24:44 - loss: 0.1191 - acc: 0.95 - ETA: 24:37 - loss: 0.1190 - acc: 0.95 - ETA: 24:30 - loss: 0.1190 - acc: 0.95 - ETA: 24:23 - loss: 0.1190 - acc: 0.95 - ETA: 24:16 - loss: 0.1196 - acc: 0.95 - ETA: 24:09 - loss: 0.1198 - acc: 0.95 - ETA: 24:02 - loss: 0.1196 - acc: 0.95 - ETA: 23:55 - loss: 0.1195 - acc: 0.95 - ETA: 23:48 - loss: 0.1194 - acc: 0.95 - ETA: 23:41 - loss: 0.1195 - acc: 0.95 - ETA: 23:34 - loss: 0.1195 - acc: 0.95 - ETA: 23:27 - loss: 0.1196 - acc: 0.95 - ETA: 23:20 - loss: 0.1194 - acc: 0.95 - ETA: 23:14 - loss: 0.1198 - acc: 0.95 - ETA: 23:07 - loss: 0.1198 - acc: 0.95 - ETA: 23:01 - loss: 0.1199 - acc: 0.95 - ETA: 22:54 - loss: 0.1197 - acc: 0.95 - ETA: 22:47 - loss: 0.1198 - acc: 0.95 - ETA: 22:40 - loss: 0.1199 - acc: 0.95 - ETA: 22:33 - loss: 0.1199 - acc: 0.95 - ETA: 22:26 - loss: 0.1199 - acc: 0.95 - ETA: 22:19 - loss: 0.1198 - acc: 0.95 - ETA: 22:13 - loss: 0.1196 - acc: 0.95 - ETA: 22:06 - loss: 0.1198 - acc: 0.95 - ETA: 21:59 - loss: 0.1200 - acc: 0.95 - ETA: 21:52 - loss: 0.1198 - acc: 0.95 - ETA: 21:46 - loss: 0.1196 - acc: 0.95 - ETA: 21:39 - loss: 0.1195 - acc: 0.95 - ETA: 21:32 - loss: 0.1195 - acc: 0.95 - ETA: 21:26 - loss: 0.1195 - acc: 0.95 - ETA: 21:19 - loss: 0.1198 - acc: 0.95 - ETA: 21:12 - loss: 0.1197 - acc: 0.95 - ETA: 21:05 - loss: 0.1195 - acc: 0.9545"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-cd1c91dbc905>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_samples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         epochs=N_EPOCHS)\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfile_handles\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile_handles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\tf-gpu\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\tf-gpu\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\tf-gpu\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\tf-gpu\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "columns = ['is_tissue','slide_path','is_tumor','is_all_tumor','tile_loc']\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "N_EPOCHS = 2\n",
    "\n",
    "for i in range(len(slide_4_test)):\n",
    "    \n",
    "    # [1] dataset , 2 pos, 2 neg, mean ratio = 3:1\n",
    "    four_samples = pd.DataFrame(columns = columns)\n",
    "    four_image_path = list()\n",
    "    four_mask_path = list()    \n",
    "    for j in range(4):\n",
    "        image_path = image_paths[slide_4_test[i][j]][1:] # 이 부분은 data 읽을때 고치자 ( [1:] 빼야함)\n",
    "        mask_path = tumor_mask_paths[slide_4_test[i][j]][1:] # 이 부분은 data 읽을때 고치자\n",
    "        samples = find_patches_from_slide(image_path, mask_path)\n",
    "        \n",
    "        four_samples = four_samples.append(samples)   \n",
    "        four_image_path.append(image_path)\n",
    "        four_mask_path.append(mask_path)\n",
    "    NUM_SAMPLES = len(four_samples)\n",
    "    if NUM_SAMPLES > 50000:\n",
    "        NUM_SAMPLES = 50000\n",
    "    \n",
    "    samples = four_samples.sample(NUM_SAMPLES, random_state=42)\n",
    "    samples.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    tumor_samples = four_samples[four_samples.is_tumor == True]\n",
    "    print(len(tumor_samples))\n",
    "    non_tumor_samples = four_samples[four_samples.is_tumor == False]\n",
    "    print(len(non_tumor_samples))\n",
    "    non_tumor_samples_3_ratio = non_tumor_samples.sample(len(tumor_samples) * 3, random_state = 42,replace=True)\n",
    "    \n",
    "    all_sample = tumor_samples.append(non_tumor_samples_3_ratio)\n",
    "\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
    "    for train_index, test_index in split.split(samples, samples[\"is_tumor\"]):\n",
    "            train_samples = samples.loc[train_index]\n",
    "            validation_samples = samples.loc[test_index]\n",
    "    \n",
    "    train_generator = gen_imgs(four_image_path,four_mask_path,train_samples, BATCH_SIZE)\n",
    "    validation_generator = gen_imgs(four_image_path,four_mask_path,validation_samples, BATCH_SIZE)\n",
    "    \n",
    "    train_start_time = datetime.now()\n",
    "    history = model.fit_generator(train_generator, np.ceil(len(train_samples) / BATCH_SIZE),\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=np.ceil(len(validation_samples) / BATCH_SIZE),\n",
    "        epochs=N_EPOCHS)\n",
    "    if file_handles != []:\n",
    "        for fh in file_handles:\n",
    "            fh.close()\n",
    "    file_handles=[]\n",
    "    #del train_generator\n",
    "    #del validation_generator\n",
    "    train_end_time = datetime.now()\n",
    "    print(\"Model training time: %.1f minutes\" % ((train_end_time - train_start_time).seconds / 60,))\n",
    "    model.save('s_1.h5')\n",
    "    # split\n",
    "    # data gen : all_image_path, all_mask_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('s_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patches in slide: 105213\n",
      "Wall time: 4min 39s\n",
      "0.9944371525566231\n"
     ]
    }
   ],
   "source": [
    "ipath = all_image_path[0]\n",
    "tpath = all_mask_path[0]\n",
    "\n",
    "all_tissue_samples = find_patches_from_slide(ipath,tpath)\n",
    "print('Total patches in slide: %d' % len(all_tissue_samples)) \n",
    "all_tissue_samples.iloc[:10]\n",
    "all_tissue_samples.is_tumor.value_counts() \n",
    "test_start_time = datetime.now()\n",
    "sample_gen = gen_imgs(all_image_path,all_mask_path,all_tissue_samples, 5000, shuffle=True)\n",
    "%time example_X, example_y  = next(sample_gen)\n",
    "test_end_time = datetime.now()\n",
    "print(\"5000 gen time: %.1f minutes\" % ((test_end_time - test_start_time).seconds / 60,))\n",
    "\n",
    "start_x = PATCH_SIZE//4\n",
    "start_y = PATCH_SIZE//4\n",
    "pred_size = PATCH_SIZE//2\n",
    "\n",
    "test_start_time = datetime.now()\n",
    "preds = []\n",
    "labels = []\n",
    "for i in range(5000):\n",
    "    prediction = predict_from_model(example_X[i],model)\n",
    "    pred_X = np.zeros((pred_size,pred_size))\n",
    "    y = example_y[i].argmax\n",
    "    for x in range(start_x,start_x+pred_size):\n",
    "        for y in range(start_y, start_y+pred_size):\n",
    "            pred_X[x-start_x][y-start_y] = prediction[x][y]\n",
    "            \n",
    "    pred_s = pd.Series(pred_X.flatten())\n",
    "    max_p = np.max(pred_s)\n",
    "    \n",
    "    y = np.max(example_y[i].argmax(axis=2))\n",
    "    preds.append(max_p)\n",
    "    labels.append(y)\n",
    "test_end_time = datetime.now()\n",
    "print(\"Model test time: %.1f minutes\" % ((test_end_time - test_start_time).seconds / 60,))    \n",
    "fpr, tpr, thresholds = metrics.roc_curve(labels,preds,pos_label=1)\n",
    "print(metrics.auc(fpr,tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patches in slide: 105213\n",
      "Wall time: 4min 41s\n",
      "5000 gen time: 4.7 minutes\n",
      "Model test time: 0.6 minutes\n",
      "0.9947376610561872\n"
     ]
    }
   ],
   "source": [
    "ipath = all_image_path[0]\n",
    "tpath = all_mask_path[0]\n",
    "\n",
    "all_tissue_samples = find_patches_from_slide(ipath,tpath)\n",
    "print('Total patches in slide: %d' % len(all_tissue_samples)) \n",
    "all_tissue_samples.iloc[:10]\n",
    "all_tissue_samples.is_tumor.value_counts() \n",
    "test_start_time = datetime.now()\n",
    "sample_gen = gen_imgs(all_image_path,all_mask_path,all_tissue_samples, 5000, shuffle=True)\n",
    "%time example_X, example_y  = next(sample_gen)\n",
    "test_end_time = datetime.now()\n",
    "print(\"5000 gen time: %.1f minutes\" % ((test_end_time - test_start_time).seconds / 60,))\n",
    "\n",
    "start_x = PATCH_SIZE//4\n",
    "start_y = PATCH_SIZE//4\n",
    "pred_size = PATCH_SIZE//2\n",
    "\n",
    "test_start_time = datetime.now()\n",
    "preds = []\n",
    "labels = []\n",
    "for i in range(5000):\n",
    "    prediction = predict_from_model(example_X[i],model)\n",
    "    pred_X = np.zeros((pred_size,pred_size))\n",
    "    y = example_y[i].argmax\n",
    "    pred_s = pd.Series(prediction.flatten())\n",
    "    max_p = np.max(pred_s)\n",
    "    \n",
    "    y = np.max(example_y[i].argmax(axis=2))\n",
    "    preds.append(max_p)\n",
    "    labels.append(y)\n",
    "test_end_time = datetime.now()\n",
    "print(\"Model test time: %.1f minutes\" % ((test_end_time - test_start_time).seconds / 60,))    \n",
    "fpr, tpr, thresholds = metrics.roc_curve(labels,preds,pos_label=1)\n",
    "print(metrics.auc(fpr,tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patches in slide: 105213\n",
      "Wall time: 4min 35s\n",
      "5000 gen time: 4.6 minutes\n",
      "Model test time: 3.4 minutes\n",
      "0.9952130818359953\n"
     ]
    }
   ],
   "source": [
    "ipath = all_image_path[0]\n",
    "tpath = all_mask_path[0]\n",
    "\n",
    "all_tissue_samples = find_patches_from_slide(ipath,tpath)\n",
    "print('Total patches in slide: %d' % len(all_tissue_samples)) \n",
    "all_tissue_samples.iloc[:10]\n",
    "all_tissue_samples.is_tumor.value_counts() \n",
    "test_start_time = datetime.now()\n",
    "sample_gen = gen_imgs(all_image_path,all_mask_path,all_tissue_samples, 5000, shuffle=True)\n",
    "%time example_X, example_y  = next(sample_gen)\n",
    "test_end_time = datetime.now()\n",
    "print(\"5000 gen time: %.1f minutes\" % ((test_end_time - test_start_time).seconds / 60,))\n",
    "\n",
    "start_x = 32\n",
    "start_y = 32\n",
    "pred_size = 192\n",
    "\n",
    "test_start_time = datetime.now()\n",
    "preds = []\n",
    "labels = []\n",
    "for i in range(5000):\n",
    "    prediction = predict_from_model(example_X[i],model)\n",
    "    pred_X = np.zeros((pred_size,pred_size))\n",
    "    y = example_y[i].argmax\n",
    "    for x in range(start_x,start_x+pred_size):\n",
    "        for y in range(start_y, start_y+pred_size):\n",
    "            pred_X[x-start_x][y-start_y] = prediction[x][y]\n",
    "            \n",
    "    pred_s = pd.Series(pred_X.flatten())\n",
    "    max_p = np.max(pred_s)\n",
    "    \n",
    "    y = np.max(example_y[i].argmax(axis=2))\n",
    "    preds.append(max_p)\n",
    "    labels.append(y)\n",
    "test_end_time = datetime.now()\n",
    "print(\"Model test time: %.1f minutes\" % ((test_end_time - test_start_time).seconds / 60,))    \n",
    "fpr, tpr, thresholds = metrics.roc_curve(labels,preds,pos_label=1)\n",
    "print(metrics.auc(fpr,tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004315432452131063"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pred_x = np.max(preds)\n",
    "max_pred_x\n",
    "\n",
    "min_pred_x = np.min(preds)\n",
    "min_pred_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test time: 0.0 minutes\n"
     ]
    }
   ],
   "source": [
    "test_start_time = datetime.now()\n",
    "slide = openslide.open_slide(ipath)\n",
    "tiles = DeepZoomGenerator(slide,tile_size=256,overlap=0, limit_bounds=False) \n",
    "test_end_time = datetime.now()\n",
    "print(\"Model test time: %.1f minutes\" % ((test_end_time - test_start_time).seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
