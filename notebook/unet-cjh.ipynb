{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Detection Model U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import openslide\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.filters import threshold_otsu\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from openslide.deepzoom import DeepZoomGenerator\n",
    "from common import find_patches_from_slide\n",
    "from model import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************** run train.py ***************************************\n"
     ]
    }
   ],
   "source": [
    "print('**************************** run train.py ***************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_handles = []\n",
    "def generator(samples,\n",
    "              slide_paths,\n",
    "              truth_paths,\n",
    "              batch_size,\n",
    "              patch_size=256,\n",
    "              shuffle=True):\n",
    "    \n",
    "    slide0 = openslide.open_slide(slide_paths[0])\n",
    "    slide1 = openslide.open_slide(slide_paths[1])\n",
    "    slide2 = openslide.open_slide(slide_paths[2])\n",
    "    slide3 = openslide.open_slide(slide_paths[3])\n",
    "    file_handles.append(slide0)\n",
    "    file_handles.append(slide1)\n",
    "    file_handles.append(slide2)\n",
    "    file_handles.append(slide3)\n",
    "\n",
    "    # tiles\n",
    "    tiles0 = DeepZoomGenerator(slide0, tile_size=patch_size, overlap=0, limit_bounds=False)\n",
    "    tiles1 = DeepZoomGenerator(slide1, tile_size=patch_size, overlap=0, limit_bounds=False)\n",
    "    tiles2 = DeepZoomGenerator(slide2, tile_size=patch_size, overlap=0, limit_bounds=False)\n",
    "    tiles3 = DeepZoomGenerator(slide3, tile_size=patch_size, overlap=0, limit_bounds=False)\n",
    "\n",
    "    start_x0, start_y0 = 0, 0\n",
    "    start_x1, start_y1 = 0, 0\n",
    "    start_x2, start_y2 = 0, 0\n",
    "    start_x3, start_y3 = 0, 0\n",
    "    if 'pos' in slide_paths[0]:\n",
    "        start_x0 = int(slide0.properties.get('openslide.bounds-x', 0)) / patch_size\n",
    "        start_y0 = int(slide0.properties.get('openslide.bounds-y', 0)) / patch_size\n",
    "        truth0 = openslide.open_slide(truth_paths[0])\n",
    "        truth_tiles0 = DeepZoomGenerator(truth0, tile_size=16,overlap=0, limit_bounds=False)\n",
    "    \n",
    "    if 'pos' in slide_paths[1]: \n",
    "        start_x1 = int(slide1.properties.get('openslide.bounds-x', 0)) / patch_size\n",
    "        start_y1 = int(slide1.properties.get('openslide.bounds-y', 0)) / patch_size\n",
    "        truth1 = openslide.open_slide(truth_paths[1])\n",
    "        truth_tiles1 = DeepZoomGenerator(truth1, tile_size=16,overlap=0, limit_bounds=False)\n",
    "        \n",
    "    if 'pos' in slide_paths[2]:\n",
    "        start_x2 = int(slide2.properties.get('openslide.bounds-x', 0)) / patch_size\n",
    "        start_y2 = int(slide2.properties.get('openslide.bounds-y', 0)) / patch_size\n",
    "        truth2 = openslide.open_slide(truth_paths[2])\n",
    "        truth_tiles2 = DeepZoomGenerator(truth2, tile_size=16, overlap=0, limit_bounds=False)\n",
    "        \n",
    "    if 'pos' in slide_paths[3]:\n",
    "        start_x3 = int(slide3.properties.get('openslide.bounds-x', 0)) / patch_size\n",
    "        start_y3 = int(slide3.properties.get('openslide.bounds-y', 0)) / patch_size\n",
    "        truth3 = openslide.open_slide(truth_paths[3])\n",
    "        truth_tiles3 = DeepZoomGenerator(truth3, tile_size=16, overlap=0, limit_bounds=False)\n",
    "        \n",
    "    num_samples = len(samples)\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            samples = samples.sample(frac=1)  # shuffling\n",
    "\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples.iloc[offset:offset+batch_size]\n",
    "\n",
    "            batch_tiles, batch_masks = [], []\n",
    "            for slide_path, (y, x) in zip(batch_samples['slide_path'].values, \n",
    "                                          batch_samples['tile_loc'].values):\n",
    "                \n",
    "                mask_tile_zoom = np.zeros((patch_size,patch_size))\n",
    "                if slide_path == slide_paths[0]:\n",
    "                    img = tiles0.get_tile(tiles0.level_count-1, (x+start_x0, y+start_y0))\n",
    "                    if 'pos' in slide_path:\n",
    "                        mask_tile = truth_tiles0.get_tile(truth_tiles0.level_count-1, (x, y))\n",
    "                        mask_tile = (cv2.cvtColor(np.array(mask_tile), cv2.COLOR_RGB2GRAY) > 0).astype(int)\n",
    "                        # mask_size_up , 16 to 256\n",
    "                        k, l = mask_tile.shape\n",
    "                        for i in range(k):\n",
    "                            for j in range(l):\n",
    "                                for o in range(16):\n",
    "                                    for p in range(16):\n",
    "                                        mask_tile_zoom[i*16+o,j*16+p] = mask_tile[i][j]\n",
    "                        \n",
    "                elif slide_path == slide_paths[1]:\n",
    "                    img = tiles1.get_tile(tiles1.level_count-1, (x+start_x1, y+start_y1))\n",
    "                    if 'pos' in slide_path:\n",
    "                        mask_tile = truth_tiles1.get_tile(truth_tiles1.level_count-1, (x, y))\n",
    "                        mask_tile = (cv2.cvtColor(np.array(mask_tile), cv2.COLOR_RGB2GRAY) > 0).astype(int)\n",
    "                        # mask_size_up , 16 to 256\n",
    "                        k, l = mask_tile.shape\n",
    "                        for i in range(k):\n",
    "                            for j in range(l):\n",
    "                                for o in range(16):\n",
    "                                    for p in range(16):\n",
    "                                        mask_tile_zoom[i*16+o,j*16+p] = mask_tile[i][j]\n",
    "                \n",
    "                elif slide_path == slide_paths[2]:\n",
    "                    img = tiles2.get_tile(tiles2.level_count-1, (x+start_x2, y+start_y2))\n",
    "                    if 'pos' in slide_path:\n",
    "                        mask_tile = truth_tiles2.get_tile(truth_tiles2.level_count-1, (x, y))\n",
    "                        mask_tile = (cv2.cvtColor(np.array(mask_tile), cv2.COLOR_RGB2GRAY) > 0).astype(int)\n",
    "                        # mask_size_up , 16 to 256\n",
    "                        k, l = mask_tile.shape\n",
    "                        for i in range(k):\n",
    "                            for j in range(l):\n",
    "                                for o in range(16):\n",
    "                                    for p in range(16):\n",
    "                                        mask_tile_zoom[i*16+o,j*16+p] = mask_tile[i][j]\n",
    "\n",
    "                elif slide_path == slide_paths[3]:\n",
    "                    img = tiles3.get_tile(tiles3.level_count-1, (x+start_x3, y+start_y3))\n",
    "                    if 'pos' in slide_path:\n",
    "                        mask_tile = truth_tiles3.get_tile(truth_tiles3.level_count-1, (x, y))\n",
    "                        mask_tile = (cv2.cvtColor(np.array(mask_tile), cv2.COLOR_RGB2GRAY) > 0).astype(int)\n",
    "                        # mask_size_up , 16 to 256\n",
    "                        k, l = mask_tile.shape\n",
    "                        for i in range(k):\n",
    "                            for j in range(l):\n",
    "                                for o in range(16):\n",
    "                                    for p in range(16):\n",
    "                                        mask_tile_zoom[i*16+o,j*16+p] = mask_tile[i][j]\n",
    "\n",
    "                \n",
    "                if img.size != (patch_size, patch_size):\n",
    "                    img = Image.new('RGB', (patch_size, patch_size))\n",
    "                    mask_tile_zoom = np.zeros((patch_size, patch_size))\n",
    "                    \n",
    "                batch_tiles.append(np.array(img))\n",
    "                batch_masks.append(mask_tile_zoom)\n",
    "                \n",
    "            # train_x & train_y\n",
    "            train_x = np.array(batch_tiles)\n",
    "            train_y = to_categorical(np.array(batch_masks), num_classes=2)\n",
    "            \n",
    "            yield train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_path():\n",
    "    slide_paths, mask_paths = {}, {}\n",
    "    with open('./train.txt', 'r') as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            path = line.rstrip('\\n')\n",
    "            slide_paths[idx] = path\n",
    "    \n",
    "    with open('./train_mask.txt', 'r') as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            path = line.rstrip('\\n')\n",
    "            mask_paths[idx] = path\n",
    "            \n",
    "    return slide_paths, mask_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_paths, mask_paths = get_data_path()\n",
    "\n",
    "slide_4_list_1 = [[102,104,29,44],[144,55,30,18],[54,65,21,36],[139,82,1,49],[105,151,15,2],[75,100,41,9],[156,113,32,37]]\n",
    "slide_4_list_2 = [[109,58,14,28],[101,69,11,43],[94,74,3,20],[64,140,17,16],[92,154,8,26],[99,60,0,33],[86,146,25,19],[68,112,38,51],\n",
    "                 [71,136,31,4],[59,91,12,6]]\n",
    "slide_4_list_3 = [[143,132,124,85],[95,120,81,77],[97,96,110,83],[152,128,149,155],[153,111,57,138],[134,135,114,76],\n",
    "                  [123,90,121,61],[147,148,119,142],[66,137,63,80],[70,79,115,133],[129,141,127,145]]\n",
    "slide_4_test = [[55,55, 0, 0]]\n",
    "\n",
    "columns = ['is_tissue','slide_path','is_tumor','is_all_tumor','tile_loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Start Train ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/D/dev/help/notebook/common.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  samples['tile_loc'] = list(samples.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "250/250 [==============================] - 259s 1s/step - loss: 13.4277 - acc: 0.8109 - val_loss: 10.5274 - val_acc: 0.8780\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "n_epochs = 1\n",
    "print('======== Start Train ========')\n",
    "for slides in slide_4_test:\n",
    "    sample_group_df = pd.DataFrame(\n",
    "            columns=['is_tissue','slide_path','is_tumor','is_all_tumor','tile_loc'])\n",
    "    \n",
    "    group_slide_path, group_mask_path = [], []\n",
    "    for idx in slides:\n",
    "        slide_path, truth_path = slide_paths[idx], mask_paths[idx]\n",
    "        slide_path  =  '.' + slide_path\n",
    "        truth_path = '.' + truth_path\n",
    "        samples = find_patches_from_slide(slide_path, truth_path)\n",
    "        sample_group_df = sample_group_df.append(samples)\n",
    "        group_slide_path.append(slide_path)\n",
    "        group_mask_path.append(truth_path)\n",
    "        \n",
    "    num_samples = len(sample_group_df)\n",
    "    if num_samples > 10000:\n",
    "        num_samples = 10000\n",
    "    \n",
    "    samples = sample_group_df.sample(num_samples, random_state=42)\n",
    "    samples.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    for train_index, test_index in split.split(samples, samples[\"is_tumor\"]):\n",
    "            train_samples = samples.loc[train_index]\n",
    "            validation_samples = samples.loc[test_index]\n",
    "            \n",
    "    train_gen = generator(train_samples, group_slide_path, group_mask_path, batch_size)\n",
    "    val_gen = generator(validation_samples, group_slide_path, group_mask_path, batch_size)\n",
    "    \n",
    "    model.fit_generator(train_gen, \n",
    "                        steps_per_epoch=np.ceil(len(train_samples)/batch_size),\n",
    "                        epochs=n_epochs,\n",
    "                        validation_data=val_gen,\n",
    "                        validation_steps=np.ceil(len(validation_samples)/batch_size),\n",
    "                        verbose=1)\n",
    "    \n",
    "    for fh in file_handles:\n",
    "        fh.close()\n",
    "    file_handles = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1/1\n",
    "250/250 [==============================] - 243s 971ms/step - loss: 0.4143 - acc: 0.8052 - val_loss: 0.4071 - val_acc: 0.8262"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************** Train finished **********************\n"
     ]
    }
   ],
   "source": [
    "model.save_weights('./data/model/unet-v2.h5')\n",
    "print('********************** Train finished **********************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
