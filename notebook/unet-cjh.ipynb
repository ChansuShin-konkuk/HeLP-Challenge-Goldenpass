{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Detection Model U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import openslide\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.filters import threshold_otsu\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from openslide.deepzoom import DeepZoomGenerator\n",
    "from common import find_patches_from_slide\n",
    "from model import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************** run train.py ***************************************\n"
     ]
    }
   ],
   "source": [
    "print('**************************** run train.py ***************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_handles = []\n",
    "def generator(samples,\n",
    "              slide_paths,\n",
    "              truth_paths,\n",
    "              batch_size,\n",
    "              patch_size=256,\n",
    "              shuffle=True):\n",
    "    \n",
    "    slide0 = openslide.open_slide(slide_paths[0])\n",
    "    slide1 = openslide.open_slide(slide_paths[1])\n",
    "    slide2 = openslide.open_slide(slide_paths[2])\n",
    "    slide3 = openslide.open_slide(slide_paths[3])\n",
    "    file_handles.append(slide0)\n",
    "    file_handles.append(slide1)\n",
    "    file_handles.append(slide2)\n",
    "    file_handles.append(slide3)\n",
    "\n",
    "    # tiles\n",
    "    tiles0 = DeepZoomGenerator(slide0, tile_size=patch_size, overlap=0, limit_bounds=False)\n",
    "    tiles1 = DeepZoomGenerator(slide1, tile_size=patch_size, overlap=0, limit_bounds=False)\n",
    "    tiles2 = DeepZoomGenerator(slide2, tile_size=patch_size, overlap=0, limit_bounds=False)\n",
    "    tiles3 = DeepZoomGenerator(slide3, tile_size=patch_size, overlap=0, limit_bounds=False)\n",
    "\n",
    "    start_x0, start_y0 = 0, 0\n",
    "    start_x1, start_y1 = 0, 0\n",
    "    start_x2, start_y2 = 0, 0\n",
    "    start_x3, start_y3 = 0, 0\n",
    "    if 'pos' in slide_paths[0]:\n",
    "        start_x0 = int(slide0.properties.get('openslide.bounds-x', 0)) / patch_size\n",
    "        start_y0 = int(slide0.properties.get('openslide.bounds-y', 0)) / patch_size\n",
    "        truth0 = openslide.open_slide(truth_paths[0])\n",
    "        truth_tiles0 = DeepZoomGenerator(truth0, tile_size=16,overlap=0, limit_bounds=False)\n",
    "    \n",
    "    if 'pos' in slide_paths[1]: \n",
    "        start_x1 = int(slide1.properties.get('openslide.bounds-x', 0)) / patch_size\n",
    "        start_y1 = int(slide1.properties.get('openslide.bounds-y', 0)) / patch_size\n",
    "        truth1 = openslide.open_slide(truth_paths[1])\n",
    "        truth_tiles1 = DeepZoomGenerator(truth1, tile_size=16,overlap=0, limit_bounds=False)\n",
    "        \n",
    "    if 'pos' in slide_paths[2]:\n",
    "        start_x2 = int(slide2.properties.get('openslide.bounds-x', 0)) / patch_size\n",
    "        start_y2 = int(slide2.properties.get('openslide.bounds-y', 0)) / patch_size\n",
    "        truth2 = openslide.open_slide(truth_paths[2])\n",
    "        truth_tiles2 = DeepZoomGenerator(truth2, tile_size=16, overlap=0, limit_bounds=False)\n",
    "        \n",
    "    if 'pos' in slide_paths[3]:\n",
    "        start_x3 = int(slide3.properties.get('openslide.bounds-x', 0)) / patch_size\n",
    "        start_y3 = int(slide3.properties.get('openslide.bounds-y', 0)) / patch_size\n",
    "        truth3 = openslide.open_slide(truth_paths[3])\n",
    "        truth_tiles3 = DeepZoomGenerator(truth3, tile_size=16, overlap=0, limit_bounds=False)\n",
    "        \n",
    "    num_samples = len(samples)\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            samples = samples.sample(frac=1)  # shuffling\n",
    "\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples.iloc[offset:offset+batch_size]\n",
    "\n",
    "            batch_tiles, batch_masks = [], []\n",
    "            for slide_path, (y, x) in zip(batch_samples['slide_path'].values, \n",
    "                                          batch_samples['tile_loc'].values):\n",
    "                \n",
    "                mask_tile_zoom = np.zeros((patch_size,patch_size))\n",
    "                if slide_path == slide_paths[0]:\n",
    "                    img = tiles0.get_tile(tiles0.level_count-1, (x+start_x0, y+start_y0))\n",
    "                    if 'pos' in slide_path:\n",
    "                        mask_tile = truth_tiles0.get_tile(truth_tiles0.level_count-1, (x, y))\n",
    "                        mask_tile = (cv2.cvtColor(np.array(mask_tile), cv2.COLOR_RGB2GRAY) > 0).astype(int)\n",
    "                        # mask_size_up , 16 to 256\n",
    "                        k, l = mask_tile.shape\n",
    "                        for i in range(k):\n",
    "                            for j in range(l):\n",
    "                                for o in range(16):\n",
    "                                    for p in range(16):\n",
    "                                        mask_tile_zoom[i*16+o,j*16+p] = mask_tile[i][j]\n",
    "                        \n",
    "                elif slide_path == slide_paths[1]:\n",
    "                    img = tiles1.get_tile(tiles1.level_count-1, (x+start_x1, y+start_y1))\n",
    "                    if 'pos' in slide_path:\n",
    "                        mask_tile = truth_tiles1.get_tile(truth_tiles1.level_count-1, (x, y))\n",
    "                        mask_tile = (cv2.cvtColor(np.array(mask_tile), cv2.COLOR_RGB2GRAY) > 0).astype(int)\n",
    "                        # mask_size_up , 16 to 256\n",
    "                        k, l = mask_tile.shape\n",
    "                        for i in range(k):\n",
    "                            for j in range(l):\n",
    "                                for o in range(16):\n",
    "                                    for p in range(16):\n",
    "                                        mask_tile_zoom[i*16+o,j*16+p] = mask_tile[i][j]\n",
    "                \n",
    "                elif slide_path == slide_paths[2]:\n",
    "                    img = tiles2.get_tile(tiles2.level_count-1, (x+start_x2, y+start_y2))\n",
    "                    if 'pos' in slide_path:\n",
    "                        mask_tile = truth_tiles2.get_tile(truth_tiles2.level_count-1, (x, y))\n",
    "                        mask_tile = (cv2.cvtColor(np.array(mask_tile), cv2.COLOR_RGB2GRAY) > 0).astype(int)\n",
    "                        # mask_size_up , 16 to 256\n",
    "                        k, l = mask_tile.shape\n",
    "                        for i in range(k):\n",
    "                            for j in range(l):\n",
    "                                for o in range(16):\n",
    "                                    for p in range(16):\n",
    "                                        mask_tile_zoom[i*16+o,j*16+p] = mask_tile[i][j]\n",
    "\n",
    "                elif slide_path == slide_paths[3]:\n",
    "                    img = tiles3.get_tile(tiles3.level_count-1, (x+start_x3, y+start_y3))\n",
    "                    if 'pos' in slide_path:\n",
    "                        mask_tile = truth_tiles3.get_tile(truth_tiles3.level_count-1, (x, y))\n",
    "                        mask_tile = (cv2.cvtColor(np.array(mask_tile), cv2.COLOR_RGB2GRAY) > 0).astype(int)\n",
    "                        # mask_size_up , 16 to 256\n",
    "                        k, l = mask_tile.shape\n",
    "                        for i in range(k):\n",
    "                            for j in range(l):\n",
    "                                for o in range(16):\n",
    "                                    for p in range(16):\n",
    "                                        mask_tile_zoom[i*16+o,j*16+p] = mask_tile[i][j]\n",
    "\n",
    "                \n",
    "                if img.size != (patch_size, patch_size):\n",
    "                    img = Image.new('RGB', (patch_size, patch_size))\n",
    "                    mask_tile_zoom = np.zeros((patch_size, patch_size))\n",
    "                    \n",
    "                batch_tiles.append(np.array(img))\n",
    "                batch_masks.append(mask_tile_zoom)\n",
    "                \n",
    "            # train_x & train_y\n",
    "            train_x = np.array(batch_tiles)\n",
    "            train_y = to_categorical(np.array(batch_masks), num_classes=2)\n",
    "            \n",
    "            yield train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_path():\n",
    "    slide_paths, mask_paths = {}, {}\n",
    "    with open('./train.txt', 'r') as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            path = line.rstrip('\\n')\n",
    "            slide_paths[idx] = path\n",
    "    \n",
    "    with open('./train_mask.txt', 'r') as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            path = line.rstrip('\\n')\n",
    "            mask_paths[idx] = path\n",
    "            \n",
    "    return slide_paths, mask_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './train.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6e1ab6beced7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mslide_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mslide_4_list_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m102\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m104\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m29\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m44\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m144\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m55\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m54\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m65\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m36\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m139\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m82\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m49\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m105\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m151\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m41\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m156\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m113\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m37\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m slide_4_list_2 = [[109,58,14,28],[101,69,11,43],[94,74,3,20],[64,140,17,16],[92,154,8,26],[99,60,0,33],[86,146,25,19],[68,112,38,51],\n\u001b[1;32m      5\u001b[0m                  [71,136,31,4],[59,91,12,6]]\n",
      "\u001b[0;32m<ipython-input-9-74dd8f52cedb>\u001b[0m in \u001b[0;36mget_data_path\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_data_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mslide_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./train.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train.txt'"
     ]
    }
   ],
   "source": [
    "slide_paths, mask_paths = get_data_path()\n",
    "\n",
    "slide_4_list_1 = [[102,104,29,44],[144,55,30,18],[54,65,21,36],[139,82,1,49],[105,151,15,2],[75,100,41,9],[156,113,32,37]]\n",
    "slide_4_list_2 = [[109,58,14,28],[101,69,11,43],[94,74,3,20],[64,140,17,16],[92,154,8,26],[99,60,0,33],[86,146,25,19],[68,112,38,51],\n",
    "                 [71,136,31,4],[59,91,12,6]]\n",
    "slide_4_list_3 = [[143,132,124,85],[95,120,81,77],[97,96,110,83],[152,128,149,155],[153,111,57,138],[134,135,114,76],\n",
    "                  [123,90,121,61],[147,148,119,142],[66,137,63,80],[70,79,115,133],[129,141,127,145]]\n",
    "slide_4_test = [[55,55, 0, 0]]\n",
    "\n",
    "columns = ['is_tissue','slide_path','is_tumor','is_all_tumor','tile_loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/data/train/image/positive/Slide003.mrxs',\n",
       " '/data/train/mask/negative/Slide001.png')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slide_paths[55], mask_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 256, 256, 3)  0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 16) 448         lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256, 256, 16) 0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 16) 2320        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 128, 16) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 32) 4640        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 128, 32) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 32) 9248        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 32)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 64)   18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64, 64, 64)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 64)   36928       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 128)  73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 128)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 128)  147584      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 128)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 256)  295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16, 16, 256)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 256)  590080      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 32, 32, 128)  131200      conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 256)  0           conv2d_transpose[0][0]           \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 128)  295040      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 128)  0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 128)  147584      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 64, 64, 64)   32832       conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 128)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 64)   73792       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64, 64, 64)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 64)   36928       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 32) 8224        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 64) 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 128, 32) 18464       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 128, 128, 32) 0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 32) 9248        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 256, 256, 16) 2064        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 32) 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 256, 16) 4624        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 256, 256, 16) 0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 256, 16) 2320        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 256, 2)  34          conv2d_17[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,941,122\n",
      "Trainable params: 1,941,122\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Start Train ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/D/dev/help/notebook/common.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  samples['tile_loc'] = list(samples.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "250/250 [==============================] - 259s 1s/step - loss: 13.4277 - acc: 0.8109 - val_loss: 10.5274 - val_acc: 0.8780\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "n_epochs = 1\n",
    "print('======== Start Train ========')\n",
    "for slides in slide_4_test:\n",
    "    sample_group_df = pd.DataFrame(\n",
    "            columns=['is_tissue','slide_path','is_tumor','is_all_tumor','tile_loc'])\n",
    "    \n",
    "    group_slide_path, group_mask_path = [], []\n",
    "    for idx in slides:\n",
    "        slide_path, truth_path = slide_paths[idx], mask_paths[idx]\n",
    "        slide_path  =  '.' + slide_path\n",
    "        truth_path = '.' + truth_path\n",
    "        samples = find_patches_from_slide(slide_path, truth_path)\n",
    "        sample_group_df = sample_group_df.append(samples)\n",
    "        group_slide_path.append(slide_path)\n",
    "        group_mask_path.append(truth_path)\n",
    "        \n",
    "    num_samples = len(sample_group_df)\n",
    "    if num_samples > 10000:\n",
    "        num_samples = 10000\n",
    "    \n",
    "    samples = sample_group_df.sample(num_samples, random_state=42)\n",
    "    samples.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    for train_index, test_index in split.split(samples, samples[\"is_tumor\"]):\n",
    "            train_samples = samples.loc[train_index]\n",
    "            validation_samples = samples.loc[test_index]\n",
    "            \n",
    "    train_gen = generator(train_samples, group_slide_path, group_mask_path, batch_size)\n",
    "    val_gen = generator(validation_samples, group_slide_path, group_mask_path, batch_size)\n",
    "    \n",
    "    model.fit_generator(train_gen, \n",
    "                        steps_per_epoch=np.ceil(len(train_samples)/batch_size),\n",
    "                        epochs=n_epochs,\n",
    "                        validation_data=val_gen,\n",
    "                        validation_steps=np.ceil(len(validation_samples)/batch_size),\n",
    "                        verbose=1)\n",
    "    \n",
    "    for fh in file_handles:\n",
    "        fh.close()\n",
    "    file_handles = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1/1\n",
    "250/250 [==============================] - 243s 971ms/step - loss: 0.4143 - acc: 0.8052 - val_loss: 0.4071 - val_acc: 0.8262"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************** Train finished **********************\n"
     ]
    }
   ],
   "source": [
    "model.save_weights('./data/model/unet-v2.h5')\n",
    "print('********************** Train finished **********************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
